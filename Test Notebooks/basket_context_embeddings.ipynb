{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Reshape, Lambda\n",
    "from keras.layers import Input, Embedding, concatenate, Multiply\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import preprocessing\n",
    "from keras.regularizers import l2\n",
    "import random\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/Users/BharathiSrinivasan/Documents/GitHub/Thesis/merged_data.csv')\n",
    "folder = 'C:\\\\Users\\\\Pascal\\\\Documents\\\\GitHub\\\\instacart-market-basket-analysis\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_big = pd.read_csv(folder + 'merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample orders of n customer\n",
    "def data_nusers(df, n):\n",
    "    unique_users = df.user_id.unique()\n",
    "    i = 0\n",
    "    df_nusers = pd.DataFrame()  \n",
    "    for user in unique_users:\n",
    "        df_nusers = df_nusers.append(df[df.user_id == user])\n",
    "        i +=1\n",
    "        if (i == n):\n",
    "            break\n",
    "    return pd.DataFrame(df_nusers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(folder + 'merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use = data_nusers(df, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use.to_csv(folder+'data1000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of product IDs available\n",
    "N_products = df_use['product_id'].nunique()\n",
    "N_shoppers = df_use['user_id'].nunique()\n",
    "\n",
    "print(N_products,N_shoppers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_COLUMNS = [\"user_id\", \"product_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper to index columns before embeddings\n",
    "def val2idx(df, cols):\n",
    "    val_types = dict()\n",
    "    for c in cols:\n",
    "        val_types[c] = df[c].unique()\n",
    "\n",
    "    val_to_idx = dict()\n",
    "    for k, v in val_types.items():\n",
    "        val_to_idx[k] = {o: i for i, o in enumerate(val_types[k])}\n",
    "\n",
    "    for k, v in val_to_idx.items():\n",
    "        df[k] = df[k].apply(lambda x: v[x]+1)\n",
    "\n",
    "    unique_vals = dict()\n",
    "    for c in cols:\n",
    "        unique_vals[c] = df[c].nunique()\n",
    "\n",
    "    return df, unique_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deep, unique_vals = val2idx(df_use, EMBEDDING_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346377, 13)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_prod(order):\n",
    "    for _,row in order.iterrows():\n",
    "        if row['add_to_cart_order']==1:\n",
    "            return row['product_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_prod(order):\n",
    "    for _,row in order.iterrows():\n",
    "        if row['add_to_cart_order']==2:\n",
    "            return row['product_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basket(order):\n",
    "    order['product_id']= order['product_id'].astype(str)\n",
    "    \n",
    "    basket = []\n",
    "    for _,row in order.iterrows():\n",
    "        if row['add_to_cart_order']!=1:\n",
    "            basket.append(row['product_id'])\n",
    "    #basket = random.shuffle(basket)\n",
    "    return basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basket_by_order(order,order_id_list, N_products):\n",
    "    names = []\n",
    "    for col in range(N_products):\n",
    "        names.append('col_' + str(col))\n",
    "    basket_df = pd.DataFrame(columns=names, index = order_id_list)\n",
    "    \n",
    "    for i in order.index:\n",
    "        list_items = order.get_value(i, 'basket')\n",
    "        for val in list_items:\n",
    "            basket_df.loc[i,'col_'+str(val)] = 1\n",
    "    basket_df.fillna(0, inplace=True)\n",
    "    \n",
    "    return basket_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom scipy.sparse import csr_matrix\\n\\n# Group interactions\\norder_product = df_deep.groupby(by=['order_id','product_id']).apply(lambda x: 1).to_dict() \\n\\n# Number of different Users / Locations\\nN_orders = df_deep.order_id.nunique()\\nN_products = df_deep.product_id.nunique()\\n\\n# Build Rating matrix\\nrow, col = zip(*(order_product.keys())) #row-> orders,  col-> products\\nmap_o = dict(zip(df_deep['order_id'].unique(),range(N_orders)))\\nmap_p = dict(zip(df_deep['product_id'].unique(),range(N_products)))\\nrow_idx = [map_o[o] for o in row]\\ncol_idx = [map_p[p] for p in col]\\ndata = np.array(order_product.values)\\nbasket_matrix = csr_matrix((data, (row_idx, col_idx)), shape=(N_orders,N_products))\\n\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Group interactions\n",
    "order_product = df_deep.groupby(by=['order_id','product_id']).apply(lambda x: 1).to_dict() \n",
    "\n",
    "# Number of different Users / Locations\n",
    "N_orders = df_deep.order_id.nunique()\n",
    "N_products = df_deep.product_id.nunique()\n",
    "\n",
    "# Build Rating matrix\n",
    "row, col = zip(*(order_product.keys())) #row-> orders,  col-> products\n",
    "map_o = dict(zip(df_deep['order_id'].unique(),range(N_orders)))\n",
    "map_p = dict(zip(df_deep['product_id'].unique(),range(N_products)))\n",
    "row_idx = [map_o[o] for o in row]\n",
    "col_idx = [map_p[p] for p in col]\n",
    "data = np.array(order_product.values)\n",
    "basket_matrix = csr_matrix((data, (row_idx, col_idx)), shape=(N_orders,N_products))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_for_embedding(df):\n",
    "    first = df.groupby(['order_id']).apply(first_prod)\n",
    "    next_product = df.groupby(['order_id']).apply(lambda x:next_prod(x))\n",
    "    basket =df.groupby(['order_id', 'product_id']).size().unstack(fill_value=0)\n",
    "    transform_df = pd.DataFrame(first, columns = ['first_prod'])\n",
    "    transform_df['next_product']= next_product.values\n",
    "    transform_df.reset_index(inplace=True)\n",
    "\n",
    "    # Number of product IDs available\n",
    "    N_products = df['product_id'].nunique()\n",
    "    N_shoppers = df['user_id'].nunique()\n",
    "\n",
    "    return transform_df, basket, N_products, N_shoppers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "df1, basket, N_products, N_shoppers = transform_data_for_embedding(df_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>product_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>19030</th>\n",
       "      <th>19031</th>\n",
       "      <th>19032</th>\n",
       "      <th>19033</th>\n",
       "      <th>19034</th>\n",
       "      <th>19035</th>\n",
       "      <th>19036</th>\n",
       "      <th>19037</th>\n",
       "      <th>19038</th>\n",
       "      <th>19039</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19039 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "product_id  1      2      3      4      5      6      7      8      9      \\\n",
       "order_id                                                                    \n",
       "2               1      1      1      1      1      1      1      1      1   \n",
       "3               0      0      0      0      0      0      0      0      0   \n",
       "4               0      0      0      0      0      0      0      0      0   \n",
       "5               0      0      0      0      0      0      0      0      0   \n",
       "6               0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "product_id  10     ...  19030  19031  19032  19033  19034  19035  19036  \\\n",
       "order_id           ...                                                    \n",
       "2               0  ...      0      0      0      0      0      0      0   \n",
       "3               0  ...      0      0      0      0      0      0      0   \n",
       "4               0  ...      0      0      0      0      0      0      0   \n",
       "5               0  ...      0      0      0      0      0      0      0   \n",
       "6               0  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "product_id  19037  19038  19039  \n",
       "order_id                         \n",
       "2               0      0      0  \n",
       "3               0      0      0  \n",
       "4               0      0      0  \n",
       "5               0      0      0  \n",
       "6               0      0      0  \n",
       "\n",
       "[5 rows x 19039 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_for_embed_network(df, transform_df, basket, N_products):\n",
    "\n",
    "    # Creating df with order_id, user_id, first prod, next prod, basket \n",
    "    x = df.drop_duplicates(subset=['order_id','user_id'])\n",
    "    train_df = pd.merge(transform_df, x[['order_id','user_id']], how='left', on='order_id' )\n",
    "    train_df.dropna(inplace=True)\n",
    "    \n",
    "    basket.reset_index(inplace=True)\n",
    "    basket_df = pd.merge(train_df[['order_id']], basket, how='left', on ='order_id')\n",
    "    basket_df.drop(['order_id'], axis=1, inplace=True)\n",
    "\n",
    "    train_df['next_product'] = train_df['next_product'].astype('category', categories = df.product_id.unique())\n",
    "    y_df = pd.get_dummies(train_df, columns = ['next_product'])\n",
    "    y_df.drop(['user_id','order_id','first_prod'], axis=1, inplace=True)\n",
    "\n",
    "    return train_df['first_prod'], train_df['user_id'], basket_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pascal\\Anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "product_in , user_in, basket_in, predicted_product = create_input_for_embed_network(df_deep, df1, basket, N_products)\n",
    "time_taken = (time.clock() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32523,) (32523,) (32523, 19039) (32523, 19039)\n"
     ]
    }
   ],
   "source": [
    "print(user_in.shape, product_in.shape, basket_in.shape, predicted_product.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pascal\\Anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"la...)`\n"
     ]
    }
   ],
   "source": [
    "# Integer IDs representing 1-hot encodings\n",
    "prior_in = Input(shape=(1,))\n",
    "shopper_in = Input(shape=(1,))\n",
    "\n",
    "# Dense N-hot encoding for candidate products\n",
    "candidates_in = Input(shape=(N_products,))\n",
    "\n",
    "# Embeddings\n",
    "prior = Embedding(N_products+1, 10)(prior_in)\n",
    "shopper = Embedding(N_shoppers+1, 10)(shopper_in)\n",
    "\n",
    "# Reshape and merge all embeddings together\n",
    "reshape = Reshape(target_shape=(10,))\n",
    "combined = keras.layers.concatenate([reshape(prior), reshape(shopper)])\n",
    "\n",
    "# Hidden layers\n",
    "#hidden_1 = Dense(1024, activation='relu',W_regularizer=l2(0.02))(combined)\n",
    "#hidden_2 = Dense(512, activation='relu',W_regularizer=l2(0.02))(hidden_1)\n",
    "hidden_3 = Dense(100, activation='relu')(combined)\n",
    "#LR1 = LeakyReLU(alpha=0.1)(hidden_3)\n",
    "hidden_4 = Dense(1, activation='relu')(hidden_3)\n",
    "\n",
    "# Final 'fan-out' into the space of future products\n",
    "final = Dense(N_products, activation='relu')(hidden_4)\n",
    "#LR_final = LeakyReLU(alpha=0.1)(final)\n",
    "\n",
    "# Ensure we do not overflow when we exponentiate\n",
    "final = Lambda(lambda x: x - K.max(x))(final)\n",
    "\n",
    "# Masked soft-max using Lambda and merge-multiplication\n",
    "exponentiate = Lambda(lambda x: K.exp(x))(final)\n",
    "masked = keras.layers.multiply([exponentiate, candidates_in])\n",
    "predicted = Lambda(lambda x: x / K.sum(x))(masked)\n",
    "\n",
    "# Compile with categorical crossentropy and adam\n",
    "mdl = Model(input=[prior_in , shopper_in, candidates_in],\n",
    "            output=predicted)\n",
    "mdl.compile(loss='categorical_crossentropy', \n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Pascal\\Anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Pascal\\Anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "history = mdl.fit([product_in , user_in, basket_in], predicted_product,  batch_size=128, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = mdl.to_json()\n",
    "with open(\"NN_embed_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "mdl.save_weights(\"NN_embed_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32485, 19039)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
