{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bayes_by_backprop.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"6KlhmzAPqQ5r","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import print_function\n","import collections\n","import mxnet as mx\n","import numpy as np\n","import pandas as pd\n","from sklearn import preprocessing\n","from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from mxnet import nd, autograd\n","from matplotlib import pyplot as plt\n","from keras.models import model_from_json, load_model \n","import math"],"execution_count":0,"outputs":[]},{"metadata":{"id":"itKIECytrGU5","colab_type":"code","colab":{}},"cell_type":"code","source":["config = {\n","    \"num_hidden_layers\": 2,\n","    \"num_hidden_units\": 400,\n","    \"batch_size\": 128,\n","    \"epochs\": 10,\n","    \"learning_rate\": 0.001,\n","    \"num_samples\": 1,\n","    \"pi\": 0.25,\n","    \"sigma_p\": 1.0,\n","    \"sigma_p1\": 0.75,\n","    \"sigma_p2\": 0.1,\n","}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GH-DGE3_raF-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"09ca1d81-25cf-484b-8d8f-576ab8e4a5ba","executionInfo":{"status":"ok","timestamp":1554891612202,"user_tz":-120,"elapsed":38869,"user":{"displayName":"Bharathi Srinivasan","photoUrl":"https://lh5.googleusercontent.com/-lYUgVd7w6A4/AAAAAAAAAAI/AAAAAAAAVl8/Zhzl1HjZgRg/s64/photo.jpg","userId":"04911370725640246255"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","root_path = 'gdrive/My Drive/BNN_RecSys/'\n","\n","df_use = pd.read_csv(root_path+\"engineered_data_100.csv\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"5_hzRjq3w1sy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"6d9ed9cb-0421-4004-e747-5b3a57da2bc2","executionInfo":{"status":"ok","timestamp":1554891681343,"user_tz":-120,"elapsed":1822,"user":{"displayName":"Bharathi Srinivasan","photoUrl":"https://lh5.googleusercontent.com/-lYUgVd7w6A4/AAAAAAAAAAI/AAAAAAAAVl8/Zhzl1HjZgRg/s64/photo.jpg","userId":"04911370725640246255"}}},"cell_type":"code","source":["# load embeddings model\n","json_file = open(root_path+'NN_embed_model.json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights(root_path+\"NN_embed_model_weights.h5\")\n","print(\"Loaded model from disk\")\n","\n","# Exctracted embeddings from pr-trained model\n","embeddings_prior = loaded_model.layers[2].get_weights()[0]\n","embeddings_user = loaded_model.layers[3].get_weights()[0]"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","Loaded model from disk\n"],"name":"stdout"}]},{"metadata":{"id":"m_nNf09ZxMxP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"8590c982-ebc9-49d6-9d62-c4c29d894522","executionInfo":{"status":"ok","timestamp":1554891725276,"user_tz":-120,"elapsed":649,"user":{"displayName":"Bharathi Srinivasan","photoUrl":"https://lh5.googleusercontent.com/-lYUgVd7w6A4/AAAAAAAAAAI/AAAAAAAAVl8/Zhzl1HjZgRg/s64/photo.jpg","userId":"04911370725640246255"}}},"cell_type":"code","source":["# Number of product IDs available\n","N_products = df_use['product_id'].nunique()\n","N_shoppers = df_use['user_id'].nunique()\n","print('Unique Products:', N_products)\n","print('Unique_Users: ', N_shoppers)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Unique Products: 6018\n","Unique_Users:  100\n"],"name":"stdout"}]},{"metadata":{"id":"41H_mwYIxOKQ","colab_type":"code","colab":{}},"cell_type":"code","source":["def val2idx(df, cols):\n","    \"\"\"\n","    Helper to index values of embedding columns\n","    \"\"\"\n","    val_types = dict()\n","    for c in cols:\n","        val_types[c] = df[c].unique()\n","\n","    val_to_idx = dict()\n","\n","    for k, v in val_types.items():\n","        val_to_idx[k] = {o: i for i, o in enumerate(val_types[k])}\n","\n","    for k, v in val_to_idx.items():\n","        df[k] = df[k].apply(lambda x: v[x]+1)\n","\n","    unique_vals = dict()\n","    for c in cols:\n","        unique_vals[c] = df[c].nunique()\n","\n","    return df, unique_vals, val_to_idx"],"execution_count":0,"outputs":[]},{"metadata":{"id":"i_5RuJmTxTkK","colab_type":"code","colab":{}},"cell_type":"code","source":["EMBEDDING_COLUMNS = [\"user_id\", \"product_id\"]\n","df_deep, values, mappings = val2idx(df_use, EMBEDDING_COLUMNS)\n","\n","df_deep.drop(['product_name','department', 'Unnamed: 0', 'index'], axis=1, inplace=True)\n","\n","CATEGORICAL_COLUMNS = [\"order_dow\", \"order_hour_of_day\",\"aisle_id\",\"department_id\"]\n","CONTINUOUS_COLUMNS = [\"days_since_prior_order\",\"order_number\",\"add_to_cart_order\",\"reordered_total\",\"product_id_orders\",\"user_distinct_products\",\"user_period\",\\\n","                     \"user_orders\",\"average_cart_position\"]\n","\n","#One-hot encoding categorical columns\n","df_deep = pd.get_dummies(df_deep, columns=[x for x in CATEGORICAL_COLUMNS])\n","\n","#Normalising the feature columns\n","df_deep[CONTINUOUS_COLUMNS] = MinMaxScaler().fit_transform(df_deep[CONTINUOUS_COLUMNS].values)\n","\n","y = df_deep.reordered.values\n","df_deep.drop(['reordered'], axis=1, inplace = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WyGiSjD4yhPn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"92833d2d-3fdd-4afa-8aee-707d048c1285","executionInfo":{"status":"ok","timestamp":1554892196363,"user_tz":-120,"elapsed":712,"user":{"displayName":"Bharathi Srinivasan","photoUrl":"https://lh5.googleusercontent.com/-lYUgVd7w6A4/AAAAAAAAAAI/AAAAAAAAVl8/Zhzl1HjZgRg/s64/photo.jpg","userId":"04911370725640246255"}}},"cell_type":"code","source":["df_deep.shape[1]"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["198"]},"metadata":{"tags":[]},"execution_count":16}]},{"metadata":{"id":"SKmcdCR7xYt9","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(df_deep, y, test_size=0.20, random_state=42, stratify=y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"p6VXYvnSyUC9","colab_type":"code","colab":{}},"cell_type":"code","source":["num_inputs = df_deep.shape[1]\n","num_outputs = 1\n","batch_size = config['batch_size']                           "],"execution_count":0,"outputs":[]},{"metadata":{"id":"_4CW2i33xiUa","colab_type":"code","colab":{}},"cell_type":"code","source":["def relu(X):\n","    return nd.maximum(X, nd.zeros_like(X))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AcnSih43xkZp","colab_type":"code","colab":{}},"cell_type":"code","source":["# Neural network modeling\n","num_layers = config['num_hidden_layers']\n","\n","# define function for evaluating MLP\n","def net(X, layer_params):\n","    layer_input = X\n","    for i in range(len(layer_params) // 2 - 2):\n","        h_linear = nd.dot(layer_input, layer_params[2*i]) + layer_params[2*i + 1]\n","        layer_input = relu(h_linear)\n","    # last layer without ReLU\n","    output = nd.dot(layer_input, layer_params[-2]) + layer_params[-1]\n","    return output\n","\n","# define network weight shapes\n","layer_param_shapes = []\n","num_hidden = config['num_hidden_units']\n","for i in range(num_layers + 1):\n","    if i == 0: # input layer\n","        W_shape = (num_inputs, num_hidden)\n","        b_shape = (num_hidden,)\n","    elif i == num_layers: # last layer\n","        W_shape = (num_hidden, num_outputs)\n","        b_shape = (num_outputs,)\n","    else: # hidden layers\n","        W_shape = (num_hidden, num_hidden)\n","        b_shape = (num_hidden,)\n","    layer_param_shapes.extend([W_shape, b_shape])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GHd5d_dIzHyP","colab_type":"code","colab":{}},"cell_type":"code","source":["# Likelihood\n","def log_softmax_likelihood(yhat_linear, y):\n","    return nd.nansum(y * nd.log_softmax(yhat_linear), axis=0, exclude=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QidWTAdc0HQj","colab_type":"code","colab":{}},"cell_type":"code","source":["# Defining Gaussian priors\n","\n","LOG2PI = np.log(2.0 * np.pi)\n","\n","def log_gaussian(x, mu, sigma):\n","    return -0.5 * LOG2PI - nd.log(sigma) - (x - mu) ** 2 / (2 * sigma ** 2)\n","\n","def gaussian_prior(x):\n","    sigma_p = nd.array([config['sigma_p']], ctx=ctx)\n","\n","    return nd.sum(log_gaussian(x, 0., sigma_p))\n","  \n","## Alternate prior: scale mixture prior\n","\n","def gaussian(x, mu, sigma):\n","    scaling = 1.0 / nd.sqrt(2.0 * np.pi * (sigma ** 2))\n","    bell = nd.exp(- (x - mu) ** 2 / (2.0 * sigma ** 2))\n","\n","    return scaling * bell\n","\n","def scale_mixture_prior(x):\n","    sigma_p1 = nd.array([config['sigma_p1']], ctx=ctx)\n","    sigma_p2 = nd.array([config['sigma_p2']], ctx=ctx)\n","    pi = config['pi']\n","\n","    first_gaussian = pi * gaussian(x, 0., sigma_p1)\n","    second_gaussian = (1 - pi) * gaussian(x, 0., sigma_p2)\n","\n","    return nd.log(first_gaussian + second_gaussian)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0XGfYyay0KOo","colab_type":"code","colab":{}},"cell_type":"code","source":["# Construct loss function as ELBO\n","def combined_loss(output, label_one_hot, params, mus, sigmas, log_prior, log_likelihood):\n","\n","    # Calculate data likelihood\n","    log_likelihood_sum = nd.sum(log_likelihood(output, label_one_hot))\n","\n","    # Calculate prior\n","    log_prior_sum = sum([nd.sum(log_prior(param)) for param in params])\n","\n","    # Calculate variational posterior\n","    log_var_posterior_sum = sum([nd.sum(log_gaussian(params[i], mus[i], sigmas[i])) for i in range(len(params))])\n","\n","    # Calculate total loss\n","    return 1.0 / num_batches * (log_var_posterior_sum - log_prior_sum) - log_likelihood_sum"],"execution_count":0,"outputs":[]},{"metadata":{"id":"l3y0E2ML0zKT","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optimizer\n","def SGD(params, lr):\n","    for param in params:\n","        param[:] = param - lr * param.grad"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LZ4TwIZN1Ab4","colab_type":"code","colab":{}},"cell_type":"code","source":["# Evaluation metric\n","def evaluate_accuracy(data_iterator, net, layer_params):\n","    numerator = 0.\n","    denominator = 0.\n","    for i, (data, label) in enumerate(data_iterator):\n","        data = data.as_in_context(ctx).reshape((-1, 784))\n","        label = label.as_in_context(ctx)\n","        output = net(data, layer_params)\n","        predictions = nd.argmax(output, axis=1)\n","        numerator += nd.sum(predictions == label)\n","        denominator += data.shape[0]\n","    return (numerator / denominator).asscalar()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"INbhph8U1FJ7","colab_type":"code","colab":{}},"cell_type":"code","source":["# Parameter initialization\n","weight_scale = .1\n","rho_offset = -3\n","\n","# initialize variational parameters; mean and variance for each weight\n","mus = []\n","rhos = []\n","\n","for shape in layer_param_shapes:\n","    mu = nd.random_normal(shape=shape, scale=weight_scale)\n","    rho = rho_offset + nd.zeros(shape=shape)\n","    mus.append(mu)\n","    rhos.append(rho)\n","\n","variational_params = mus + rhos"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8rmuFF8b2t2j","colab_type":"code","colab":{}},"cell_type":"code","source":["for param in variational_params:\n","    param.attach_grad()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ks5cD1ZL2ycA","colab_type":"code","colab":{}},"cell_type":"code","source":["# Main training loop\n","def sample_epsilons(param_shapes):\n","    epsilons = [nd.random_normal(shape=shape, loc=0., scale=1.0) for shape in param_shapes]\n","    return epsilons\n","  \n","def softplus(x):\n","    return nd.log(1. + nd.exp(x))\n","\n","def transform_rhos(rhos):\n","    return [softplus(rho) for rho in rhos]\n","  \n","def transform_gaussian_samples(mus, sigmas, epsilons):\n","    samples = []\n","    for j in range(len(mus)):\n","        samples.append(mus[j] + sigmas[j] * epsilons[j])\n","    return samples"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LxHM2b1wArzT","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train.reset_index(inplace=True)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZTNRpkkuAwKD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"ae789b81-0fb9-4955-e7ff-c142db93d178","executionInfo":{"status":"ok","timestamp":1554895834011,"user_tz":-120,"elapsed":1638,"user":{"displayName":"Bharathi Srinivasan","photoUrl":"https://lh5.googleusercontent.com/-lYUgVd7w6A4/AAAAAAAAAAI/AAAAAAAAVl8/Zhzl1HjZgRg/s64/photo.jpg","userId":"04911370725640246255"}}},"cell_type":"code","source":["X_train.drop(['index'],axis=1, inplace=True)"],"execution_count":56,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"metadata":{"id":"jVvwi-Cj29IG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":232},"outputId":"c2bd92ea-852b-4bcb-dcea-b7b178551989","executionInfo":{"status":"error","timestamp":1554895837978,"user_tz":-120,"elapsed":734,"user":{"displayName":"Bharathi Srinivasan","photoUrl":"https://lh5.googleusercontent.com/-lYUgVd7w6A4/AAAAAAAAAAI/AAAAAAAAVl8/Zhzl1HjZgRg/s64/photo.jpg","userId":"04911370725640246255"}}},"cell_type":"code","source":["# Complete training loop\n","\n","epochs = config['epochs']\n","learning_rate = config['learning_rate']\n","smoothing_constant = .01\n","train_acc = []\n","test_acc = []\n","\n","for e in range(epochs):\n","  for i in range(int(X_train.shape[0]/32)):\n","    i+=1\n","    data = np.ndarray(X_train.loc[(i-1)*32 : i*32])\n","    label = y_train[(i-1)*32, i*32]\n","    #label_one_hot = nd.one_hot(label, 2)\n","\n","    with autograd.record():\n","      # sample epsilons from standard normal\n","      epsilons = sample_epsilons(layer_param_shapes)\n","\n","      # compute softplus for variance\n","      sigmas = transform_rhos(rhos)\n","\n","      # obtain a sample from q(w|theta) by transforming the epsilons\n","      layer_params = transform_gaussian_samples(mus, sigmas, epsilons)\n","\n","      # forward-propagate the batch\n","      output = net(data, layer_params)\n","\n","      # calculate the loss\n","      loss = combined_loss(output, label, layer_params, mus, sigmas, gaussian_prior, log_softmax_likelihood)\n","\n","      # backpropagate for gradient calculation\n","      loss.backward()\n","\n","      # apply stochastic gradient descent to variational parameters\n","      SGD(variational_params, learning_rate)\n","\n","      # calculate moving loss for monitoring convergence\n","      curr_loss = nd.mean(loss).asscalar()\n","      moving_loss = (curr_loss if ((i == 0) and (e == 0)) else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n","\n","\n","      test_accuracy = evaluate_accuracy(X_test, net, mus)\n","      train_accuracy = evaluate_accuracy(X_train, net, mus)\n","      train_acc.append(np.asscalar(train_accuracy))\n","      test_acc.append(np.asscalar(test_accuracy))\n","      print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" %\n","            (e, moving_loss, train_accuracy, test_accuracy))\n","\n","plt.plot(train_acc)\n","plt.plot(test_acc)\n","plt.show()"],"execution_count":57,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-25102e34b622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#label_one_hot = nd.one_hot(label, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: sequence too large; cannot be greater than 32"]}]},{"metadata":{"id":"_lh_7SXY8Zem","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"25a2fa6d-38a7-4014-c966-bbd09e04bd87","executionInfo":{"status":"ok","timestamp":1554895768203,"user_tz":-120,"elapsed":932,"user":{"displayName":"Bharathi Srinivasan","photoUrl":"https://lh5.googleusercontent.com/-lYUgVd7w6A4/AAAAAAAAAAI/AAAAAAAAVl8/Zhzl1HjZgRg/s64/photo.jpg","userId":"04911370725640246255"}}},"cell_type":"code","source":["X_train.index"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Int64Index([2004262,  585478, 2180168,  960588, 2032816, 2354607,  163371,\n","            1264868, 1359153, 1585117,\n","            ...\n","              88733,  504370, 1604522, 1752943,  382450, 2041371, 1531510,\n","              68213,   17057, 1811363],\n","           dtype='int64', length=1920119)"]},"metadata":{"tags":[]},"execution_count":52}]}]}